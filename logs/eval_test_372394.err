Map:   0%|          | 0/164 [00:00<?, ? examples/s]Map:   1%|          | 1/164 [00:00<00:22,  7.28 examples/s]Map: 100%|██████████| 164/164 [00:00<00:00, 322.70 examples/s]
Map:   0%|          | 0/164 [00:00<?, ? examples/s]Map: 100%|██████████| 164/164 [00:00<00:00, 1730.16 examples/s]
Loading safetensors checkpoint shards:   0% Completed | 0/17 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   6% Completed | 1/17 [00:57<15:20, 57.50s/it]
Loading safetensors checkpoint shards:  12% Completed | 2/17 [01:29<10:33, 42.26s/it]
Loading safetensors checkpoint shards:  18% Completed | 3/17 [01:43<06:55, 29.66s/it]
Loading safetensors checkpoint shards:  24% Completed | 4/17 [02:02<05:27, 25.21s/it]
Loading safetensors checkpoint shards:  29% Completed | 5/17 [02:17<04:19, 21.64s/it]
Loading safetensors checkpoint shards:  35% Completed | 6/17 [02:29<03:22, 18.40s/it]
Loading safetensors checkpoint shards:  41% Completed | 7/17 [02:42<02:44, 16.50s/it]
Loading safetensors checkpoint shards:  47% Completed | 8/17 [02:53<02:15, 15.00s/it]
Loading safetensors checkpoint shards:  53% Completed | 9/17 [03:06<01:53, 14.21s/it]
Loading safetensors checkpoint shards:  59% Completed | 10/17 [03:18<01:33, 13.40s/it]
Loading safetensors checkpoint shards:  65% Completed | 11/17 [03:29<01:17, 12.96s/it]
Loading safetensors checkpoint shards:  71% Completed | 12/17 [03:42<01:04, 12.95s/it]
Loading safetensors checkpoint shards:  76% Completed | 13/17 [03:55<00:51, 12.99s/it]
Loading safetensors checkpoint shards:  82% Completed | 14/17 [04:08<00:38, 12.83s/it]
Loading safetensors checkpoint shards:  88% Completed | 15/17 [04:20<00:25, 12.64s/it]
Loading safetensors checkpoint shards:  94% Completed | 16/17 [04:33<00:12, 12.78s/it]
Loading safetensors checkpoint shards: 100% Completed | 17/17 [04:46<00:00, 12.90s/it]
Loading safetensors checkpoint shards: 100% Completed | 17/17 [04:46<00:00, 16.88s/it]

Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:24,  1.41it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:23,  1.41it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:02<00:21,  1.52it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:20,  1.54it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:03<00:18,  1.60it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:17,  1.62it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:04<00:16,  1.67it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:16,  1.68it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:05<00:15,  1.69it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:06<00:14,  1.72it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:06<00:14,  1.70it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:07<00:13,  1.70it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:07<00:13,  1.67it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:08<00:12,  1.67it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:09<00:11,  1.68it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:09<00:11,  1.66it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:10<00:11,  1.62it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:11<00:10,  1.59it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:11<00:10,  1.51it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:12<00:10,  1.49it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:13<00:09,  1.48it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:13<00:08,  1.49it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:14<00:08,  1.48it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:15<00:07,  1.45it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:15<00:06,  1.58it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:16<00:05,  1.65it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:16<00:04,  1.69it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:17<00:04,  1.73it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:17<00:03,  1.76it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:18<00:02,  1.87it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:18<00:02,  1.92it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:19<00:01,  1.82it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:19<00:01,  1.92it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:20<00:00,  1.98it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:21<00:00,  1.52it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:21<00:00,  1.63it/s]
[rank0]: Traceback (most recent call last):
[rank0]:   File "/net/scratch/jingyang/ShorterBetter/eval/Coding/human_eval/evaluate_human_eval.py", line 124, in <module>
[rank0]:     problems = problems.add_column("completion", completions)
[rank0]:                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/jingyang22/.conda/envs/rp/lib/python3.12/site-packages/datasets/arrow_dataset.py", line 560, in wrapper
[rank0]:     out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
[rank0]:                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/jingyang22/.conda/envs/rp/lib/python3.12/site-packages/datasets/fingerprint.py", line 442, in wrapper
[rank0]:     out = func(dataset, *args, **kwargs)
[rank0]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/jingyang22/.conda/envs/rp/lib/python3.12/site-packages/datasets/arrow_dataset.py", line 5703, in add_column
[rank0]:     table = concat_tables([dataset._data, column_table], axis=1)
[rank0]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/jingyang22/.conda/envs/rp/lib/python3.12/site-packages/datasets/table.py", line 1766, in concat_tables
[rank0]:     return ConcatenationTable.from_tables(tables, axis=axis)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/jingyang22/.conda/envs/rp/lib/python3.12/site-packages/datasets/table.py", line 1471, in from_tables
[rank0]:     blocks = _extend_blocks(blocks, table_blocks, axis=axis)
[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/jingyang22/.conda/envs/rp/lib/python3.12/site-packages/datasets/table.py", line 1463, in _extend_blocks
[rank0]:     result, blocks = _split_both_like(result, blocks)
[rank0]:                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/jingyang22/.conda/envs/rp/lib/python3.12/site-packages/datasets/table.py", line 1453, in _split_both_like
[rank0]:     raise ValueError("Failed to concatenate on axis=1 because tables don't have the same number of rows")
[rank0]: ValueError: Failed to concatenate on axis=1 because tables don't have the same number of rows
[rank0]:[W213 11:20:44.474673904 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
/home/jingyang22/.conda/envs/rp/lib/python3.12/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
